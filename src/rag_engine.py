import os
import shutil
from langchain_community.document_loaders import DirectoryLoader, TextLoader, PyPDFLoader, Docx2txtLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_chroma import Chroma
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate

class EnterpriseRAG:
    def __init__(self, persist_directory="./chroma_db"):
        self.persist_directory = persist_directory
        self.vector_store = None
        # Báº¢O Máº¬T 1: Láº¥y Key tá»« biáº¿n mÃ´i trÆ°á»ng (An toÃ n hÆ¡n hard-code)
        self.api_key = os.getenv("GOOGLE_API_KEY")

   def index_knowledge_base(self):
        # 1. XÃ³a DB cÅ©
        if os.path.exists(self.persist_directory):
            try: shutil.rmtree(self.persist_directory)
            except: pass

        if not os.path.exists("data"): return "ThÆ° má»¥c 'data' trá»‘ng."

        all_documents = []
        print("--- Äang quÃ©t vÃ  phÃ¢n loáº¡i tÃ i liá»‡u ---")

        # 2. QuÃ©t tá»«ng thÆ° má»¥c con Ä‘á»ƒ gáº¯n tháº» (Metadata)
        # Duyá»‡t qua cÃ¡c folder con trong 'data': HR, IT, Production...
        for category in os.listdir("data"):
            category_path = os.path.join("data", category)
            
            # Chá»‰ xá»­ lÃ½ náº¿u lÃ  thÆ° má»¥c
            if os.path.isdir(category_path):
                print(f"ğŸ“‚ Äang xá»­ lÃ½ danh má»¥c: {category}")
                
                docs = []
                # Load TXT
                try: docs.extend(DirectoryLoader(category_path, glob="**/*.txt", loader_cls=TextLoader, loader_kwargs={'encoding': 'utf-8'}, silent_errors=True).load())
                except: pass
                # Load PDF
                try: docs.extend(DirectoryLoader(category_path, glob="**/*.pdf", loader_cls=PyPDFLoader, silent_errors=True).load())
                except: pass
                # Load Word
                try: docs.extend(DirectoryLoader(category_path, glob="**/*.docx", loader_cls=Docx2txtLoader, silent_errors=True).load())
                except: pass

                # QUAN TRá»ŒNG: Gáº¯n tháº» category cho tá»«ng trang tÃ i liá»‡u
                for doc in docs:
                    doc.metadata["category"] = category  # VÃ­ dá»¥: category = "HR"
                
                all_documents.extend(docs)

        if not all_documents: return "KhÃ´ng tÃ¬m tháº¥y tÃ i liá»‡u nÃ o."

        # 3. Chia nhá» vÄƒn báº£n
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=200)
        texts = text_splitter.split_documents(all_documents)

        # 4. Táº¡o Vector Store vá»›i Metadata
        if self.api_key:
            embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001", google_api_key=self.api_key)
            try:
                self.vector_store = Chroma.from_documents(documents=texts, embedding=embeddings, persist_directory=self.persist_directory)
                return f"âœ… ÄÃ£ há»c xong {len(all_documents)} tÃ i liá»‡u chia theo cÃ¡c danh má»¥c."
            except Exception as e:
                return f"âŒ Lá»—i Indexing: {str(e)}"
        return "Thiáº¿u API Key."

   # ThÃªm tham sá»‘ category=None (Máº·c Ä‘á»‹nh lÃ  tÃ¬m táº¥t cáº£ náº¿u khÃ´ng chá»‰ Ä‘á»‹nh)
    def retrieve_answer(self, query, category=None):
        if not self.api_key: return "ChÆ°a cáº¥u hÃ¬nh API Key."
            
        embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001", google_api_key=self.api_key)
        self.vector_store = Chroma(persist_directory=self.persist_directory, embedding_function=embeddings)
        
        llm = ChatGoogleGenerativeAI(
            model="gemini-1.5-pro",
            google_api_key=self.api_key, 
            temperature=0.3,
            max_output_tokens=8192
        )
        
        # --- Cáº¤U HÃŒNH "Tá»° NHIÃŠN & CÃ NHÃ‚N HÃ“A" ---
        llm = ChatGoogleGenerativeAI(
            model="gemini-3-pro-preview",
            google_api_key=self.api_key, 
            temperature=0.3,        # TÄƒng nháº¹ lÃªn 0.3 Ä‘á»ƒ vÄƒn phong má»m máº¡i, bá»›t mÃ¡y mÃ³c (nhÆ°ng váº«n chuáº©n xÃ¡c)
            max_output_tokens=8192, # Cho phÃ©p tráº£ lá»i dÃ i Ä‘áº§y Ä‘á»§
            timeout=None,
            max_retries=2
        )
        
        # --- PROMPT: Táº O NÃŠN TÃNH CÃCH (PERSONA) ---
        template = """Báº¡n lÃ  "Trá»£ lÃ½ HR Táº­n tÃ¢m" cá»§a Takagi Viá»‡t Nam. 
        Báº¡n khÃ´ng pháº£i lÃ  cÃ¡i mÃ¡y Ä‘á»c luáº­t, mÃ  lÃ  ngÆ°á»i Ä‘á»“ng hÃ nh giÃºp nhÃ¢n viÃªn giáº£i quyáº¿t váº¥n Ä‘á».

        Ngá»¯ cáº£nh (ThÃ´ng tin ná»™i bá»™):
        {context}

        CÃ¢u há»i cá»§a nhÃ¢n viÃªn: "{question}"

        HÆ¯á»šNG DáºªN TRáº¢ Lá»œI (Báº¢O Máº¬T & Tá»° NHIÃŠN):
        1. **Giá»ng vÄƒn:** ThÃ¢n thiá»‡n, lá»‹ch sá»±, dÃ¹ng tá»« ngá»¯ "chÃºng ta", "báº¡n", "cÃ´ng ty". TrÃ¡nh dÃ¹ng tá»« ngá»¯ quÃ¡ hÃ nh chÃ­nh cá»©ng nháº¯c.
        2. **Sá»± tháº¥u cáº£m:** Náº¿u cÃ¢u há»i liÃªn quan Ä‘áº¿n quyá»n lá»£i (á»‘m Ä‘au, thai sáº£n, ká»· luáº­t), hÃ£y báº¯t Ä‘áº§u báº±ng sá»± chia sáº» hoáº·c tráº¥n an (VÃ­ dá»¥: "MÃ¬nh ráº¥t tiáº¿c nghe tin báº¡n á»‘m...", "Vá» váº¥n Ä‘á» nÃ y, báº¡n Ä‘á»«ng lo láº¯ng quÃ¡...").
        3. **TrÃ¬nh bÃ y:** - Giáº£i thÃ­ch ngáº¯n gá»n trÆ°á»›c.
           - Náº¿u cÃ³ sá»‘ liá»‡u/quy trÃ¬nh phá»©c táº¡p -> DÃ¹ng Báº£ng Markdown hoáº·c Gáº¡ch Ä‘áº§u dÃ²ng.
           - LuÃ´n trÃ­ch dáº«n nguá»“n vÄƒn báº£n (VÃ­ dá»¥: Theo Äiá»u 5 - Ná»™i quy...).
           - Pháº£i tráº£ lá»i háº¿t Ã½, khÃ´ng Ä‘Æ°á»£c dá»«ng giá»¯a chá»«ng.
           - Náº¿u báº£ng dá»¯ liá»‡u quÃ¡ dÃ i, hÃ£y tÃ¡ch thÃ nh nhiá»u báº£ng nhá» hoáº·c dÃ¹ng danh sÃ¡ch gáº¡ch Ä‘áº§u dÃ²ng (bullet points) Ä‘á»ƒ Ä‘áº£m báº£o hiá»ƒn thá»‹ Ä‘á»§ ná»™i dung.
           - TÃ¹y tá»«ng ná»™i dung cáº§n thiáº¿t, cÃ³ thá»ƒ thá»ƒ hiá»‡n báº±ng Ä‘á»“ há»a cho trá»±c quan.           
        4. **Báº£o máº­t:** Chá»‰ tráº£ lá»i dá»±a trÃªn thÃ´ng tin Ä‘Æ°á»£c cung cáº¥p. Tuyá»‡t Ä‘á»‘i khÃ´ng bá»‹a Ä‘áº·t hoáº·c tiáº¿t lá»™ thÃ´ng tin lÆ°Æ¡ng thÆ°á»Ÿng cá»§a ngÆ°á»i khÃ¡c náº¿u khÃ´ng cÃ³ trong ngá»¯ cáº£nh.
        5. **Káº¿t thÃºc:** LuÃ´n Ä‘á» nghá»‹ há»— trá»£ thÃªm (VÃ­ dá»¥: "Náº¿u cáº§n máº«u Ä‘Æ¡n, báº¡n cá»© báº£o mÃ¬nh nhÃ©!").

        PHáº¢N Há»’I Cá»¦A Báº N:"""
        
        QA_CHAIN_PROMPT = PromptTemplate.from_template(template)
        
       # --- Ká»¸ THUáº¬T FILTERING (Lá»ŒC) ---
        search_kwargs = {"k": 6}
        
        # Náº¿u ngÆ°á»i dÃ¹ng chá»‰ Ä‘á»‹nh tÃ¬m trong HR, chá»‰ tÃ¬m tÃ i liá»‡u cÃ³ metadata category='HR'
        if category and category != "All":
            search_kwargs["filter"] = {"category": category}
            print(f"ğŸ” Äang lá»c tÃ¬m kiáº¿m trong danh má»¥c: {category}")

        retriever = self.vector_store.as_retriever(search_kwargs=search_kwargs)
        
        qa_chain = RetrievalQA.from_chain_type(
            llm=llm,
            chain_type="stuff",
            retriever=retriever,
            chain_type_kwargs={"prompt": QA_CHAIN_PROMPT}
        )
        
        return qa_chain.invoke(query)["result"]
        
